{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SparkSession, Window, functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"data_exploration\")\n",
    "         .config(\"spark.driver.memory\", \"2g\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the exploration, we use a few month worth of data from 2003 that know to contain a heatwave from the assignment description.\n",
    "\n",
    "Each file has several lines of headers that we need to strip (starting with \"#\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_input_rdd = (sc\n",
    "                   .textFile(\"../data/kis_tot_200304\", 2)\n",
    "                   .map(lambda x: x.split(\",\")[0])\n",
    "                   .filter(lambda x: not x.startswith(\"#\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "parsed_input_rdd.take(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The file appears to be in a fixed width format. The columns can be parsed by extracting partial strings using the column width given by a text editor. This is brittle and will only work if all files have the same column widths.\n",
    "\n",
    "The fields in the data that we need to parse are:\n",
    "\n",
    "| Field                | Description                                                         |\n",
    "|----------------------|---------------------------------------------------------------------|\n",
    "| `DTG`                | date of measurement                                                 |\n",
    "| `LOCATION`           | location of the meteorological station                              |\n",
    "| `NAME`               | name of the meteorological station                                  |\n",
    "| `LATITUDE`           | in degrees (WGS84)                                                  |\n",
    "| `LONGITUDE`          | in degrees (WGS84)                                                  |\n",
    "| `ALTITUDE`           | in 0.1 m relative to Mean Sea Level (MSL)                           |\n",
    "| `U_BOOL_10`          | air humidity code boolean 10' unit                                  |\n",
    "| `T_DRYB_10`          | air temperature 10' unit Celcius degrees                            |\n",
    "| `TN_10CM_PAST_6H_10` | air temperature minimum 0.1m 10' unit Celcius degrees               |\n",
    "| `T_DEWP_10`          | air temperature derived dewpoint - 10' unit Celcius degrees         |\n",
    "| `T_DEWP_SEA_10`      | air temperature derived dewpoint- sea 10' unit Celcius degrees      |\n",
    "| `T_DRYB_SEA_10`      | air temperature height oil platform 10 minutes unit Celcius degrees |\n",
    "| `TN_DRYB_10`         | air temperature minimum 10' unit Celcius degrees                    |\n",
    "| `T_WETB_10`          | air temperature derived wet bulb- 10' unit Celcius degrees          |\n",
    "| `TX_DRYB_10`         | air temperature maximum 10' unit Celcius degrees                    |\n",
    "| `U_10`               | relative air humidity 10' unit %                                    |\n",
    "| `U_SEA_10`           | is relative sea air humidity 10' unit %                             |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def parse_float(string_to_parse: str):\n",
    "    string = string_to_parse.rstrip()\n",
    "    if string == \"\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(string_to_parse)\n",
    "\n",
    "\n",
    "def parse_datetime(string_to_parse: str):\n",
    "    string = string_to_parse.rstrip()\n",
    "    return datetime.strptime(string, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def parse_row(row: str):\n",
    "    return Row(\n",
    "        dtg=parse_datetime(row[:21]),\n",
    "        location=row[21:41].rstrip(),\n",
    "        name=row[41:89].rstrip(),\n",
    "        latitude=parse_float(row[89:109]),\n",
    "        longitude=parse_float(row[109:129]),\n",
    "        altitude=parse_float(row[129:149]),\n",
    "        u_bool_10=parse_float(row[149:169]),\n",
    "        t_dryb_10=parse_float(row[169:189]),\n",
    "        tn_10cm_past_6h_10=parse_float(row[189:209]),\n",
    "        t_dewp_10=parse_float(row[209:229]),\n",
    "        t_dewp_sea_10=parse_float(row[229:249]),\n",
    "        t_dryb_sea_10=parse_float(row[249:269]),\n",
    "        tn_dryb_10=parse_float(row[269:289]),\n",
    "        t_wetb_10=parse_float(row[289:309]),\n",
    "        tx_dryb_10=parse_float(row[309:329]),\n",
    "        u_10=parse_float(row[329:349]),\n",
    "        u_sea_10=parse_float(row[349:]),\n",
    "    )\n",
    "\n",
    "parsed_input_rdd = parsed_input_rdd.map(lambda x: parse_row(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "parsed_input_rdd.take(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we are only interested in data for the weather station `De Bilt` indicated by the Location `260_T_a`, we filter other records out."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "parsed_input_rdd = parsed_input_rdd.filter(lambda row: row.location == \"260_T_a\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "parsed_input_rdd.take(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For calculating heat and cold waves, we only care about the fields:\n",
    "1. datetime (DTG)\n",
    "2. temperature (T_DRYB_10)\n",
    "3. minimum temperature (TN_DRYB_10)\n",
    "4. maximum temperature (TX_DRYB_10)\n",
    "\n",
    "We can disregard all other fields for further exploration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "parsed_input_rdd = (\n",
    "    parsed_input_rdd\n",
    "    .map(lambda row: Row(dt=row.dtg, temperature=row.t_dryb_10, min_temperature=row.tn_dryb_10, max_temperature=row.tx_dryb_10))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "parsed_input_rdd.take(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make our live a bit easier for a further dive into the data, we create a DataFrame from the RDD to access functions at a higher level of abstraction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "schema = (\n",
    "    StructType()\n",
    "    .add(\"dt\", TimestampType())\n",
    "    .add(\"temperature\", DoubleType())\n",
    "    .add(\"min_temperature\", DoubleType())\n",
    "    .add(\"max_temperature\", DoubleType())\n",
    ")\n",
    "\n",
    "df = (\n",
    "    spark\n",
    "    .createDataFrame(parsed_input_rdd, schema=schema)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We aggregate the data to identify missing values, and identify potential outliers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "stats_df = (\n",
    "    df\n",
    "    # .groupBy(\n",
    "    #     f.year(\"dt\").alias(\"year\")\n",
    "    # )\n",
    "    .agg(\n",
    "        f.count(\"*\").alias(\"num_rows\"),\n",
    "        f.count(\"dt\").alias(\"num_dates\"),\n",
    "        f.count(\"temperature\").alias(\"num_temps\"),\n",
    "        f.min(\"temperature\").alias(\"min_temp\"),\n",
    "        f.max(\"temperature\").alias(\"max_temp\"),\n",
    "        f.count(\"min_temperature\").alias(\"num_min_temps\"),\n",
    "        f.min(\"min_temperature\").alias(\"min_min_temp\"),\n",
    "        f.max(\"min_temperature\").alias(\"max_min_temp\"),\n",
    "        f.count(\"max_temperature\").alias(\"num_max_temps\"),\n",
    "        f.min(\"max_temperature\").alias(\"min_max_temp\"),\n",
    "        f.max(\"max_temperature\").alias(\"max_max_temp\"),\n",
    "    )\n",
    "    # .orderBy(\"year\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "stats_df.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SparkSession, Window, functions as f\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/16 19:52:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"local[*]\")\n",
    "         .appName(\"data_exploration\")\n",
    "         .config(\"spark.driver.memory\", \"2g\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://192.168.0.16:4040'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On visual inspection, each file has several lines of headers that we need to strip (starting with \"#\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_input_rdd = (sc\n",
    "                   .textFile(\"../data/kis_tot_2*\", 2)\n",
    "                   .map(lambda x: x.split(\",\")[0])\n",
    "                   .filter(lambda x: not x.startswith(\"#\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2003-04-01 00:10:00  235_T_obs           De Kooy waarneemterrein                         52.926944           4.781111            1.2                 1                   3.1                 1.4                 2.2                                                         3.1                 2.716426            3.2                 94                                      ',\n",
       " '2003-04-01 00:20:00  235_T_obs           De Kooy waarneemterrein                         52.926944           4.781111            1.2                 1                   3.3                 1.7                 2.4                                                         3.1                 2.913063            3.3                 94                                      ',\n",
       " '2003-04-01 00:30:00  235_T_obs           De Kooy waarneemterrein                         52.926944           4.781111            1.2                 1                   3.4                 1.9                 2.5                                                         3.2                 3.011368            3.4                 94                                      ',\n",
       " '2003-04-01 00:40:00  235_T_obs           De Kooy waarneemterrein                         52.926944           4.781111            1.2                 1                   3.5                 2                   2.6                                                         3.4                 3.10967             3.5                 94                                      ',\n",
       " '2003-04-01 00:50:00  235_T_obs           De Kooy waarneemterrein                         52.926944           4.781111            1.2                 1                   3.7                 2.3                 2.8                                                         3.5                 3.30629             3.7                 94                                      ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_input_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file appears to be in a fixed width format. The columns can be parsed by extracting partial strings using the column width given by a text editor. This is brittle and will only work if all files have the same column widths.\n",
    "\n",
    "The fields in the data that we need to parse are:\n",
    "\n",
    "| Field                | Description                                                         |\n",
    "|----------------------|---------------------------------------------------------------------|\n",
    "| `DTG`                | date of measurement                                                 |\n",
    "| `LOCATION`           | location of the meteorological station                              |\n",
    "| `NAME`               | name of the meteorological station                                  |\n",
    "| `LATITUDE`           | in degrees (WGS84)                                                  |\n",
    "| `LONGITUDE`          | in degrees (WGS84)                                                  |\n",
    "| `ALTITUDE`           | in 0.1 m relative to Mean Sea Level (MSL)                           |\n",
    "| `U_BOOL_10`          | air humidity code boolean 10' unit                                  |\n",
    "| `T_DRYB_10`          | air temperature 10' unit Celcius degrees                            |\n",
    "| `TN_10CM_PAST_6H_10` | air temperature minimum 0.1m 10' unit Celcius degrees               |\n",
    "| `T_DEWP_10`          | air temperature derived dewpoint - 10' unit Celcius degrees         |\n",
    "| `T_DEWP_SEA_10`      | air temperature derived dewpoint- sea 10' unit Celcius degrees      |\n",
    "| `T_DRYB_SEA_10`      | air temperature height oil platform 10 minutes unit Celcius degrees |\n",
    "| `TN_DRYB_10`         | air temperature minimum 10' unit Celcius degrees                    |\n",
    "| `T_WETB_10`          | air temperature derived wet bulb- 10' unit Celcius degrees          |\n",
    "| `TX_DRYB_10`         | air temperature maximum 10' unit Celcius degrees                    |\n",
    "| `U_10`               | relative air humidity 10' unit %                                    |\n",
    "| `U_SEA_10`           | is relative sea air humidity 10' unit %                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_float(string_to_parse: str):\n",
    "    string = string_to_parse.rstrip()\n",
    "    if string == \"\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(string_to_parse)\n",
    "\n",
    "\n",
    "def parse_datetime(string_to_parse: str):\n",
    "    string = string_to_parse.rstrip()\n",
    "    return datetime.strptime(string, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def parse_row(row: str):\n",
    "    return Row(\n",
    "        dtg=parse_datetime(row[:21]),\n",
    "        location=row[21:41].rstrip(),\n",
    "        name=row[41:89].rstrip(),\n",
    "        latitude=parse_float(row[89:109]),\n",
    "        longitude=parse_float(row[109:129]),\n",
    "        altitude=parse_float(row[129:149]),\n",
    "        u_bool_10=parse_float(row[149:169]),\n",
    "        t_dryb_10=parse_float(row[169:189]),\n",
    "        tn_10cm_past_6h_10=parse_float(row[189:209]),\n",
    "        t_dewp_10=parse_float(row[209:229]),\n",
    "        t_dewp_sea_10=parse_float(row[229:249]),\n",
    "        t_dryb_sea_10=parse_float(row[249:269]),\n",
    "        tn_dryb_10=parse_float(row[269:289]),\n",
    "        t_wetb_10=parse_float(row[289:309]),\n",
    "        tx_dryb_10=parse_float(row[309:329]),\n",
    "        u_10=parse_float(row[329:349]),\n",
    "        u_sea_10=parse_float(row[349:]),\n",
    "    )\n",
    "\n",
    "parsed_input_rdd = parsed_input_rdd.map(lambda x: parse_row(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dtg=datetime.datetime(2003, 4, 1, 0, 10), location='235_T_obs', name='De Kooy waarneemterrein', latitude=52.926944, longitude=4.781111, altitude=1.2, u_bool_10=1.0, t_dryb_10=3.1, tn_10cm_past_6h_10=1.4, t_dewp_10=2.2, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=3.1, t_wetb_10=2.716426, tx_dryb_10=3.2, u_10=94.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 20), location='235_T_obs', name='De Kooy waarneemterrein', latitude=52.926944, longitude=4.781111, altitude=1.2, u_bool_10=1.0, t_dryb_10=3.3, tn_10cm_past_6h_10=1.7, t_dewp_10=2.4, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=3.1, t_wetb_10=2.913063, tx_dryb_10=3.3, u_10=94.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 30), location='235_T_obs', name='De Kooy waarneemterrein', latitude=52.926944, longitude=4.781111, altitude=1.2, u_bool_10=1.0, t_dryb_10=3.4, tn_10cm_past_6h_10=1.9, t_dewp_10=2.5, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=3.2, t_wetb_10=3.011368, tx_dryb_10=3.4, u_10=94.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 40), location='235_T_obs', name='De Kooy waarneemterrein', latitude=52.926944, longitude=4.781111, altitude=1.2, u_bool_10=1.0, t_dryb_10=3.5, tn_10cm_past_6h_10=2.0, t_dewp_10=2.6, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=3.4, t_wetb_10=3.10967, tx_dryb_10=3.5, u_10=94.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 50), location='235_T_obs', name='De Kooy waarneemterrein', latitude=52.926944, longitude=4.781111, altitude=1.2, u_bool_10=1.0, t_dryb_10=3.7, tn_10cm_past_6h_10=2.3, t_dewp_10=2.8, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=3.5, t_wetb_10=3.30629, tx_dryb_10=3.7, u_10=94.0, u_sea_10=None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_input_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are only interested in data for the weather station `De Bilt` indicated by the Location `260_T_a`, we filter other records out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_input_rdd = parsed_input_rdd.filter(lambda row: row.location == \"260_T_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(dtg=datetime.datetime(2003, 4, 1, 0, 10), location='260_T_a', name='De Bilt', latitude=52.098889, longitude=5.179722, altitude=1.9, u_bool_10=1.0, t_dryb_10=0.8, tn_10cm_past_6h_10=-4.8, t_dewp_10=0.4, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=0.4, t_wetb_10=0.684949, tx_dryb_10=1.2, u_10=98.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 20), location='260_T_a', name='De Bilt', latitude=52.098889, longitude=5.179722, altitude=1.9, u_bool_10=1.0, t_dryb_10=0.8, tn_10cm_past_6h_10=-4.8, t_dewp_10=0.5, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=0.7, t_wetb_10=0.684949, tx_dryb_10=0.8, u_10=98.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 30), location='260_T_a', name='De Bilt', latitude=52.098889, longitude=5.179722, altitude=1.9, u_bool_10=1.0, t_dryb_10=0.9, tn_10cm_past_6h_10=-4.8, t_dewp_10=0.6, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=0.6, t_wetb_10=0.784415, tx_dryb_10=0.9, u_10=98.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 40), location='260_T_a', name='De Bilt', latitude=52.098889, longitude=5.179722, altitude=1.9, u_bool_10=1.0, t_dryb_10=0.6, tn_10cm_past_6h_10=-5.1, t_dewp_10=0.4, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=0.6, t_wetb_10=0.485988, tx_dryb_10=0.9, u_10=98.0, u_sea_10=None),\n",
       " Row(dtg=datetime.datetime(2003, 4, 1, 0, 50), location='260_T_a', name='De Bilt', latitude=52.098889, longitude=5.179722, altitude=1.9, u_bool_10=1.0, t_dryb_10=0.6, tn_10cm_past_6h_10=-5.1, t_dewp_10=0.3, t_dewp_sea_10=None, t_dryb_sea_10=None, tn_dryb_10=0.5, t_wetb_10=0.485988, tx_dryb_10=0.8, u_10=98.0, u_sea_10=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_input_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculating heat and cold waves, we only care about the fields:\n",
    "1. datetime (DTG)\n",
    "2. temperature (T_DRYB_10)\n",
    "3. minimum temperature (TN_DRYB_10)\n",
    "4. maximum temperature (TX_DRYB_10)\n",
    "\n",
    "We can disregard all other fields for further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_input_rdd = (\n",
    "    parsed_input_rdd\n",
    "    .map(lambda row: Row(dt=row.dtg, temperature=row.t_dryb_10, min_temperature=row.tn_dryb_10, max_temperature=row.tx_dryb_10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(dt=datetime.datetime(2003, 4, 1, 0, 10), temperature=0.8, min_temperature=0.4, max_temperature=1.2),\n",
       " Row(dt=datetime.datetime(2003, 4, 1, 0, 20), temperature=0.8, min_temperature=0.7, max_temperature=0.8),\n",
       " Row(dt=datetime.datetime(2003, 4, 1, 0, 30), temperature=0.9, min_temperature=0.6, max_temperature=0.9),\n",
       " Row(dt=datetime.datetime(2003, 4, 1, 0, 40), temperature=0.6, min_temperature=0.6, max_temperature=0.9),\n",
       " Row(dt=datetime.datetime(2003, 4, 1, 0, 50), temperature=0.6, min_temperature=0.5, max_temperature=0.8)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_input_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our live a bit easier for a further dive into the data, we create a DataFrame from the RDD to access functions at a higher level of abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (\n",
    "    StructType()\n",
    "    .add(\"dt\", TimestampType())\n",
    "    .add(\"temperature\", DoubleType())\n",
    "    .add(\"min_temperature\", DoubleType())\n",
    "    .add(\"max_temperature\", DoubleType())\n",
    ")\n",
    "\n",
    "df = (\n",
    "    spark\n",
    "    .createDataFrame(parsed_input_rdd, schema=schema)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+---------------+---------------+\n",
      "|                 dt|temperature|min_temperature|max_temperature|\n",
      "+-------------------+-----------+---------------+---------------+\n",
      "|2003-04-01 00:10:00|        0.8|            0.4|            1.2|\n",
      "|2003-04-01 00:20:00|        0.8|            0.7|            0.8|\n",
      "|2003-04-01 00:30:00|        0.9|            0.6|            0.9|\n",
      "|2003-04-01 00:40:00|        0.6|            0.6|            0.9|\n",
      "|2003-04-01 00:50:00|        0.6|            0.5|            0.8|\n",
      "+-------------------+-----------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate the data to identify missing values, and identify potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = (\n",
    "    df\n",
    "    .groupBy(\n",
    "        f.year(\"dt\").alias(\"year\")\n",
    "    )\n",
    "    .agg(\n",
    "        f.count(\"*\").alias(\"num_rows\"),\n",
    "        f.count(\"dt\").alias(\"num_dates\"),\n",
    "        f.count(\"temperature\").alias(\"num_temps\"),\n",
    "        f.min(\"temperature\").alias(\"min_temp\"),\n",
    "        f.max(\"temperature\").alias(\"max_temp\"),\n",
    "        f.count(\"min_temperature\").alias(\"num_min_temps\"),\n",
    "        f.min(\"min_temperature\").alias(\"min_min_temp\"),\n",
    "        f.max(\"min_temperature\").alias(\"max_min_temp\"),\n",
    "        f.count(\"max_temperature\").alias(\"num_max_temps\"),\n",
    "        f.min(\"max_temperature\").alias(\"min_max_temp\"),\n",
    "        f.max(\"max_temperature\").alias(\"max_max_temp\"),\n",
    "    )\n",
    "    .orderBy(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>(935 + 2) / 937]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+---------+--------+--------+-------------+------------+------------+-------------+------------+------------+\n",
      "|year|num_rows|num_dates|num_temps|min_temp|max_temp|num_min_temps|min_min_temp|max_min_temp|num_max_temps|min_max_temp|max_max_temp|\n",
      "+----+--------+---------+---------+--------+--------+-------------+------------+------------+-------------+------------+------------+\n",
      "|2003|   39599|    39599|    39565|    -7.2|    34.6|        39560|        -7.3|        34.4|        39560|        -7.0|        35.0|\n",
      "|2004|   52560|    52560|    52408|    -7.7|    32.3|        52399|        -7.8|        32.0|        52399|        -7.5|        32.5|\n",
      "|2005|   52560|    52560|    52539|   -14.4|    32.7|        52530|       -14.4|        32.5|        52530|       -14.1|        32.8|\n",
      "|2006|   52560|    52560|    52516|    -6.9|    35.5|        52513|        -7.3|        35.1|        52513|        -6.6|        35.7|\n",
      "|2007|   52560|    52560|    52510|    -6.8|    31.4|        52508|        -6.9|        31.2|        52508|        -6.7|        31.6|\n",
      "|2008|   52704|    52704|    52697|    -8.7|    30.9|        52692|        -8.7|        30.5|        52692|        -8.6|        31.2|\n",
      "|2009|   52560|    52560|    52556|   -11.3|    33.8|        52552|       -11.5|        33.2|        52552|       -11.1|        33.8|\n",
      "|2010|   52416|    52416|    52366|   -11.1|    34.2|        52363|       -11.1|        34.0|        52363|       -11.1|        34.4|\n",
      "|2011|   52560|    52560|    52528|    -6.4|    32.1|        52524|        -6.4|        32.0|        52524|        -6.2|        32.2|\n",
      "|2012|   52704|    52704|    52702|   -18.8|    32.9|        52701|       -18.9|        32.8|        52701|       -18.8|        33.0|\n",
      "|2013|   52560|    52560|    52543|   -12.9|    33.9|        52536|       -13.0|        33.8|        52536|       -12.6|        34.0|\n",
      "|2014|   52560|    52560|    52545|    -3.3|    32.9|        52541|        -3.3|        32.5|        52541|        -3.2|        32.9|\n",
      "|2015|   51264|    51264|    50475|    -5.7|    33.0|        50473|        -5.7|        32.9|        50473|        -5.6|        33.1|\n",
      "|2016|   52560|    52560|    52516|    -7.8|    32.9|        52509|        -8.0|        32.4|        52509|        -7.7|        32.9|\n",
      "|2017|   52560|    52560|    52500|    -7.3|    31.7|        52499|        -7.4|        31.5|        52499|        -7.2|        31.9|\n",
      "|2018|   52560|    52560|    52540|    -8.5|    35.7|        52537|        -8.5|        35.2|        52537|        -8.4|        35.7|\n",
      "|2019|   52560|    52560|    52551|    -8.0|    37.3|        52547|        -8.1|        37.2|        52547|        -8.0|        37.5|\n",
      "|2020|   30673|    30673|    30653|    -4.2|    31.9|        30652|        -4.3|        31.9|        30652|        -4.2|        32.0|\n",
      "+----+--------+---------+---------+--------+--------+-------------+------------+------------+-------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stats_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observations:\n",
    "* As we can see from the monthly input files, we don't have data for all month in the years 2003 and 2020.\n",
    "* There should be 52560 records (one for each 10 minutes; 60 * 24 * 365 / 10) in each regular year and 52704 records in a leap year. For most years, we have complete data. Exceptions are 2010 with 52416 records, and 2015 with 51264 records. Given this, the data should be reasonably complete. As we will disregard missing data, there's no need to further worry about this.\n",
    "* The window functions-based algorithm aggregates the records by day. As only max/min aggregations are used, we don't need to take care of duplicates.\n",
    "* There are no unreasonable temperature outliers that would need further investigation.\n",
    "* The minimum and maximum temperature columns' min and max values are close to the temperature columns min and max values across all years, giving no indication for a closer look.\n",
    "* Compared to the temperature column (t_dryb_10), the minimum temperature(tn_dryb_10) and maximum temperature (tn_dryb_10) columns have a few  more missing readings (less than a dozen per year). To fill in those blanks, we can consider coalescing min/max temperature columns and the temperature column."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
